<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

        <title>V. Petras: Geospatial analytics for point clouds in an open science framework</title>

        <meta name="description" content="Dissertation defense: Turning point clouds, surfaces, and their time series into information in a framework of open geospatial science">
        <meta name="author" content="Vaclav Petras">

        <meta name="apple-mobile-web-app-capable" content="yes" />
        <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

        <link rel="stylesheet" href="css/reveal.css">
        <link rel="stylesheet" href="css/theme/ncsu-geoforall-lab.css" id="theme">

        <!-- For syntax highlighting -->
        <link rel="stylesheet" href="lib/css/zenburn.css">
        <!-- For chalkboard plugin -->
        <link rel="stylesheet" href="css/font-awesome.min.css">

        <!-- If the query includes 'print-pdf', include the PDF print sheet -->
        <!-- Printing and PDF exports -->
        <script>
            var link = document.createElement( 'link' );
            link.rel = 'stylesheet';
            link.type = 'text/css';
            link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
            document.getElementsByTagName( 'head' )[0].appendChild( link );
        </script>

        <!--[if lt IE 9]>
        <script src="lib/js/html5shiv.js"></script>
        <![endif]-->

        <style>
            body {
                background-image: url("img/v_profile_points_same_height.png");
                background-repeat: repeat-x;
                background-position: left 99%;
                background-size: auto 5%;
            }

            .glow {
                text-shadow: 0 0 20px white, 0 0 18px white, 0 0 16px white, 0 0 14px white, 0 0 12px white, 0 0 10px white, 0 0 8px white, 0 0 6px white;
            }

            .reveal .box-glow {
                box-shadow: 0px 0px 15px 0px white, 0px 0px 10px 0px white, 0px 0px 5px 0px white;
            }
        </style>

    </head>

    <body>

        <div class="reveal">

            <!-- Any section element inside of this container is displayed as a slide -->
            <div class="slides">
<section>
    <h3>Dissertation Defense</h3>
    <h2>
        Geospatial Analytics
        for Point Clouds
        <br>
        in an Open Science Framework
    </h2>
    <h3 style="margin-top: 0.5em">
        Vaclav (Vashek) Petras</h3>
    <p class="title-foot">
        <a href="https://www.ncsu.edu/" title="North Carolina State University">North Carolina State University</a>
        <br>
        <a href="https://geospatial.ncsu.edu/geoforall/" title="NCSU GeoForAll Lab">GeoForAll Lab</a>
        at
        <a href="https://geospatial.ncsu.edu/" title="NCSU Center for Geospatial Analytics">Center for Geospatial Analytics</a>
        <br>
    </p>
    <p>April 23, 2018</p>
    <p><a href="https://wenzeslaus.github.io/dissertation-presentation/">wenzeslaus.github.io/dissertation-presentation</a></p>
</section>


<!-- intro -->


<section>
    <h3>Point Clouds</h3>
    <ul>
        <li>set of points in 3D space
        <li>&ldquo;a lot of XYZ coordinates&rdquo;
        <li>sources
            <ul>
                <li>airborne lidar
                <li>terrestrial lidar
                <li>SfM-derived (based on UAV imagery)
                <li>short-range sensors
            </ul>
    </ul>
    <br>
    <img class="stretch" src="img/sensors_schema.png">
</section>


<section>
    <h3>Point Cloud Usages</h3>
    <ul>
        <li>flood modeling <small>[e.g., Webster et al. 2010]</small>
        <li>wildfire fuel assessment <small>[e.g., Gajardo et al. 2014]</small>
        <li>habitat characterization <small>[e.g., Sasaki et al. 2016]</small>
        <li>land cover classification <small>[e.g., Antonarakis et al. 2008]</small>
        <li>...
    </ul>
    <br>
    <img style="width: 50%;" src="img/lidar_groud_nonground.png">
</section>


<section>
    <h3>Outline</h3>
    <ul>
        <li>Point densities in point clouds
        <li>Description of 3D vegetation structure
        <li>Reproducibility and open science
            <!-- enabling code reuse and thorough review -->
            <ul>
                <li>Go to
                    <a href="https://codeocean.com/2018/04/21/generalized-3d-fragmentation-index-derived-from-lidar-point-clouds/" title="Goes directly to the capsule">
                        codeocean.com
                    </a>
                <li>Search for &ldquo;petras&rdquo;
                <li>Select &ldquo;Generalized 3D Fragmentation Index Derived From Lidar Point Clouds&rdquo;
                <li>Run the code
                    <a href="https://codeocean.com/2018/04/21/generalized-3d-fragmentation-index-derived-from-lidar-point-clouds/" title="Link to the capsule">
                    <img style="display: inline; height: 1em; margin: 0px; padding: 0px; border-radius: 3px;" src="img/codeocean_run_button.png">
                    </a>
                <li>Create an account <small>(name, email, password + ToU &amp; PP + confirmation email)</small>
            </ul>
    </ul>
    <br>
    <img class="stretch" src="img/codeocean_frag_code.png">
</section>


<!-- density -->


<section>
    <h2>Point Densities in Point Clouds</h2>
    <small>
        Density Anomalies in Point Clouds (Chapter 2)
        <br>
        Homogenization and Decimation of Point Clouds (Chapter 3)
    </small>
</section>


<section>
    <h3>Point Densities</h3>
    <ul>
        <li>spatial distribution of points in a point cloud
    </ul>
    <img style="width: 100%;" src="img/natural_planted_forest_gray.png">
    <br>
    <img style="width: 100%;" src="img/skewness_figure.png">
    <br>
    <small>
        natural and planted forest (transect)
        distinguished by vertical distribution of points
    </small>
</section>


<section>
    <h3>Use of Point Densities</h3>
    <ul>
        <li>vegetation structure <small>[e.g., Sasaki et al. 2016]</small>
        <li>subcanopy solar radiation <small>[e.g., Bode et al. 2014]</small>
        <li>biomass estimation <small>[e.g., Calders et al. 2015]</small>
        <li>leaf area density distribution <small>[e.g., Oshio et al. 2015]</small>
        <li>crown density <small>[e.g., Dalponte et al. 2009]</small>
        <li>...
    </ul>
    <br>
    <img class="stretch" src="img/dark_tree.png">
</section>


<section>
    <h3>Questions</h3>
<ul>
    <li>
        What are the different density anomalies and associated issues?
        <ul>
            <li>Issue for density-dependent products, processing speed, &hellip;
        </ul>
    <li>
        What are their causes and solutions?
</ul>
</section>


<section>
    <h3>Airborne Lidar Example: Scan Line Densities</h3>
    <ul>
        <li>issue: high density at the end of the line
        <li>cause: mechanics of the scanner
        <li>associated elevation error: may indicate low quality points
    </ul>
    <br>
    <img class="stretch" src="img/scan_line_end.png">
    <br>
    <small>detail of an end of scan line</small>
</section>


<section>
    <h3>Airborne Lidar Example: Swath Overlaps</h3>
    <ul>
        <li>issue: doubled density
        <li>cause: necessary swath overlaps
        <li>associated elevation error: may indicate abrupt changes in elevation
    </ul>
    <br>
    <img class="stretch" src="img/complete_lidar_survey.png">
    <br>
    <small>point density of a complete survey</small>
</section>


<section>
    <h3>Airborne Lidar Example: Banding</h3>
    <ul>
        <li>issue: doubled density
        <li>cause: necessary swath overlaps
        <li>associated elevation error: may be associated with bended elevations
    </ul>
    <br>
    <img class="stretch" src="img/banding_density.png">
    <br>
    <small>density waves (banding)</small>
</section>


<section>
    <h3>SfM-Derived Point Cloud Example</h3>
    <ul>
        <li>issue: high density of points for vegetation, but ground missing
        <li>cause: images capture only top of canopy
    </ul>
    <img class="stretch" src="img/profile_uav_lidar.png">
    <br>
    <small>vertical point distribution in lidar and SfM-derived point clouds</small>
</section>


<section>
    <h3>Terrestrial Lidar Example: Overall Point Distribution</h3>
    <ul>
        <li>issue: different density and vertical distribution of points
        <li>cause: each method produces point clouds with very different properties
        <li>associated processing challenge: increased processing time
    </ul>
    <img class="stretch" src="img/count_ground_single.png">
    <br>
    <small>terrestrial lidar (raster resolution 0.5 m, red color used for 80 to 18 thousand points per cell)</small>
</section>


<!-- decimation -->


<section>
    <h3>Homogenization &amp; Decimation</h3>

<ul>
    <li>decimation ~ thinning ~ sampling
    <li>makes the point cloud smaller, more manageable
    <li>count-based decimation: preserves variations in density
    <li>grid-based decimation ~ binning: removes variations in density
</ul>

<br>

<img style="width: 30%;margin-bottom:0px" src="img/decimation_secref_full.png">
<img style="width: 30%;margin-bottom:0px" src="img/decimation_secref_preserve_3.png">
<img style="width: 30%;margin-bottom:0px" src="img/decimation_secref_grid_10.png">
<br>
<span style="margin-left:20px;margin-right:30px">original point cloud</span>
<span style="margin-left:0px;margin-right:5px">count-based decimation</span>
<span style="margin-left:20px">grid-based decimation</span>

</section>


<section>
    <h3>Questions</h3>
<ul>
    <li>
        Which decimation performs better for topography and microtopography?
    <li>
        How does this change with the point cloud acquisition method?
    <li>
        Are the simplest decimations enough?
        Or do we need to use slower but more sophisticated techniques?
</ul>
</section>


<section>
    <h3>Evaluating Level of Detail</h3>

<ul>
    <li>microtopography <small>[e.g., Watt 1947]</small>:
        small variations in topography
    <li>local relief model <small>[Hesse 2010]</small>:
        features other than trend
</ul>

<br>

<img style="width: 40%;" src="img/gully_shaded_relief.png">
<img style="width: 40%;" src="img/gully_lrm.png">

<br>

<small>
sub-meter features: 30-60cm wide, 30cm deep, 60m long gully and tillage (resolution 30cm)
<!-- 294 rows, 325 cols (88.2m x 97.5m) -->
</small>

<!--
Watt, Alex S. "Pattern and process in the plant community." Journal of ecology 35.1/2 (1947): 1-22.

Environmental Engineering Dictionary
Refers to the contours along the bottom of a shallow wetland system.
A complex microtopography creates a great variety of environmental
conditions that favor the unique requirements of many different species
of marsh plants.
http://www.ecologydictionary.org/MICROTOPOGRAPHY
-->

</section>


<section>
<h3>Influence of Grid-Based Decimation Resolution</h3>

<img style="width: 20%;" src="img/uav_grid_points_res_0_1_shaded_elevation.png">

<img style="width: 20%;" src="img/uav_grid_points_res_0_3_shaded_elevation.png">

<img style="width: 20%;" src="img/uav_grid_points_res_0_9_shaded_elevation.png">

<img style="width: 20%;" src="img/uav_grid_points_res_1_5_shaded_elevation.png">

<img style="width: 20%;" src="img/uav_grid_points_res_0_1_lrm_shaded.png">

<img style="width: 20%;" src="img/uav_grid_points_res_0_3_lrm_shaded.png">

<img style="width: 20%;" src="img/uav_grid_points_res_0_9_lrm_shaded.png">

<img style="width: 20%;" src="img/uav_grid_points_res_1_5_lrm_shaded.png">

<small>
grid size: 0.1 m &rarr; 0.3 m &rarr; 0.9 m &rarr; 1.5 m
<br>
<small>
(points removed: 0 % &rarr; 81 % &rarr; 98 % &rarr; 99 %)
</small>
</small>

</section>


<section>
    <h3>Removing Points</h3>
    <div class="left">
    <h4>Airborne Lidar</h4>
    <ul>
        <li>count-based and grid-based decimations are equivalent
    </ul>
    <br>
    <img style="width: 100%;" src="img/lrm_grid_count_lidar.png">
    </div>
    <div class="right">
    <h4>Terrestrial Lidar</h4>
    <ul>
        <li>grid-based decimation performs better
    </ul>
    <br>
    <img style="width: 100%;" src="img/lrm_grid_count_ground.png">
    </div>
</section>


<section>
    <h3>Contributions</h3>
    <ul>
        <li>identification of density anomalies, their causes, resulting issues, and solutions
        <li>significant decimation is possible with (micro)topography preserved
            <ul>
                <li>with data from all 4 tested sensors
            </ul>
        <li>faster and simpler count-based decimation more advantageous
            <ul>
                <li>in most cases count-based decimation provided same results as grid-based decimation
                <li>needed when relative density needs to be preserved
            </ul>
        <li>more complex grid-based decimation needed for specific cases
            <ul>
                <li>beneficial for terrestrial lidar data
                <li>beneficial for homogenization
            </ul>
    </ul>
</section>


<section>
    <h3>Publications</h3>
    <h4>Published</h4>
    Petras, V., A. Petrasova, J. Jeziorska, and H. Mitasova (2016). <em>Processing UAV
    and lidar point clouds in GRASS GIS</em>. In: ISPRS-International Archives of the
    Photogrammetry, Remote Sensing and Spatial Information Sciences XLI-B7, p. 945–952.
    <a href="https://doi.org/10.5194/isprs-archives-XLI-B7-945-2016">DOI&nbsp;10.5194/isprs-archives-XLI-B7-945-2016</a>
    <br>
    <small>[675 reads on ResearchGate, Apr 16, 2018]</small>
    <h4 style="padding-top: 1em;">To Be Submitted</h4>
    <em>Density anomalies in point clouds (Chapter 2)</em>.
    <br>
    Target journal: MDPI Remote Sensing
    <br>
    <img class="stretch" src="img/papers/petras2016processing_page.png">
</section>


<section>
    <h3>Software</h3>
    <ul>
        <li>extended GRASS GIS module for binning (r.in.lidar)
        <li>created GRASS GIS module for binning in 3D (r3.in.lidar)
        <li>created module for count- and grid-based decimation (v.decimate)
        <li>extended GRASS GIS module for point cloud import (v.in.lidar)
        <li>local relief model implementation for GRASS GIS (r.local.relief)
        <li>point cloud transect (v.profile.points)
    </ul>
    <br>
    <img class="stretch" src="img/v_profile_points_alternate.png">
</section>


<section>
    <h3>Educational Material</h3>
    <p>
    <em>Processing lidar and UAV point clouds in GRASS GIS</em>
    available online
    <br>
    (and translated to Spanish by GRASS GIS community).
    </p>
    <h3 style="padding-top: 1ex;">Training</h3>
    Workshop at FOSS4G 2017 in Boston,
    <br>
    Center for Geographic Analysis, Harvard University.
</section>


<!-- 3D fragmentation -->


<section>
    <h2>Description of 3D Structure<br>in Lidar Point Clouds</h2>
    <small>
        Generalized 3D Fragmentation Index Derived from Lidar Point Clouds (Chapter 4)
    </small>
</section>


<section>
    <h3>Lidar Point Clouds</h3>
    <ul>
        <li>lidar penetrates vegetation <small>(not only top of canopy)</small>
        <li>points in the vegetation <small>(not only ground points)</small>
        <li>vegetation-related applications
            <ul>
                <li>habitat characterization
                    <small>[e.g., Sasaki et al. 2016]</small>
                <li>fuel modeling
                    <small>[e.g., García et al. 2011]</small>
                <li>tree models
                    <small>[e.g., Gorte &amp; Winterhalder 2004]</small>
                <li>...
            </ul>
        <li>challenging to process <small>(large, unstructured, 3D)</small>
    </ul>
    <br>
    <img class="stretch" src="img/points.png">
</section>


<section>
    <h3>Questions</h3>
<ul>
    <li>
        Is 3D raster representation appropriate for lidar data analysis?
    <li>
        How to derive and describe 3D structure captured in lidar point clouds?
    <li>
        Is a 2D landscape index extensible and applicable to 3D vegetation structure?
</ul>
</section>


<section>
    <h3>3D Raster</h3>
    <img class="stretch" src="img/raster3d_plain.png">
    <br>
    <small>voxel-based (cube-based) representation of space</small>
</section>


<section>
    <h3>2D Forest Fragmentation Index</h3>
    <img class="stretch" src="img/forestfrag_2d_forest.png">
    <br>
    <small>forested areas</small>
</section>


<section>
    <h3>2D Forest Fragmentation Index</h3>
    <img class="stretch" src="img/forestfrag_2d_index.png">
    <br>
    <small>forest fragmentation index [Riitters et al. 2000]</small>
</section>


<section>
    <h3>Generalized Fragmentation Index</h3>
    <div class="left" style="max-width:41% !important">
    <img style="width: 100%;" src="img/ff_graph.png">
    <br>
    <small>assignment of fragmentation classes<br> [Riitters et al. 2000], generalized</small>
    </div>
    <ul class="right" style="max-width:55% !important">
        <li>number of occupied cells in moving window
        <li>number of partially occupied cell pairs in moving window
        <li>number of fully occupied cell pairs in moving window
        <li>generalized equations for 3D
            <ul>
                <li>3D moving window
                <li>interior limit added
                <li>interior based on circle equation
                <li>customizable limits (classes)
            </ul>
        <li>used for vegetation scale, not landscape scale
    </ul>
</section>


<section>
    <h3>Point Cloud and Presence Profiles</h3>
    <img class="stretch" src="img/profiles_points_and_presence.png">
    <br>
    <small>
        slice of raw point cloud
        and slice of 3D raster with cells marked as presence or absence
    </small>
</section>


<section>
    <h3>Point Cloud and Index Profiles</h3>
    <img class="stretch" src="img/profiles_points_and_ff.png">
    <br>
    <small>
        slice of raw point cloud
        and slice of fragmentation index 3D raster
    </small>
</section>


<section>
    <h3>Fragmentation Index 3D Raster</h3>
    <img class="stretch" src="img/index_animation.gif">
    <br>
    <small>profiles of the fragmentation index 3D raster</small>
</section>


<section>
    <h3>3D Raster as 2D Rasters</h3>
    <ul>
        <li>using count of cells of the same class for each vertical column
    </ul>
    <img class="stretch" src="img/count_relative_perforated_interior.png">
    <br>
    <small>relative count of perforated and interior* class cells in a vertical column</small>
    <br>
    <small style="font-size: 75%;">*under top of the canopy</small>
</section>


<section>
    <h3>Comparison with Point Density</h3>
    <ul>
        <li>Index is based on presence, absence, and spatial distribution of points.
        <li>Is there any difference between the most common index class and density?
    </ul>
    <img class="stretch" src="img/ff_and_density.png" title="Fragmentation and density (modified from computed image - mask applied)">
    <br>
    <small>most common class in vertical column and point density</small>
</section>


<section>
    <h3>Contributions</h3>
    <ul>
        <li>3D raster representation is suitable for lidar data analysis
            of vegetation structure
        <li>2D remote sensing and landscape ecology concepts can be
            applied in 3D
        <li>generalized 3D fragmentation index is now available
        <li>aggregation method resulting in a 2D raster is also available
    </ul>
</section>


<section>
    <h3>Publication</h3>
    Petras, V., D. J. Newcomb, and H. Mitasova. 2017.
    <em>Generalized 3D fragmentation index derived from lidar point clouds</em>.
    In: Open Geospatial Data, Software and Standards 2(9).
    <a href="https://doi.org/10.1186/s40965-017-0021-8">DOI&nbsp;10.1186/s40965-017-0021-8</a>
    <br>
    <small>[Accessed 1351 times at SpringerOpen, Apr 16, 2018]</small>
    <br>
    <img class="stretch" src="img/papers/petras2017generalized_page.png">
</section>


<section>
    <h3>Software</h3>
    <ul>
        <li>3D fragmentation index (r3.forestfrag)
        <li>revised 2D fragmentation index (r.forestfrag)
        <li>dominant fragmentation class (r3.count.categories)
        <li>profile/slice of a 3D raster (r3.profile)
        <li>3D scatter plot of 3D raster (r3.scatterplot)
        <li>3D scatter plot of 2D raster (r.scatterplot)
    </ul>
    <br>
    <img class="stretch" src="img/r3_scatterplot.png">
</section>


<!-- open geospatial science -->


<section>
    <h2>A Publication Framework<br>for Open Science</h2>
    <small>
        A Framework for Open Geospatial Science (Chapter 6)
        <br>
        Integrating Free and Open Source Solutions into Geospatial Science Education (Chapter 7)
    </small>
</section>

<section>
    <h3>Reproducibility of Computational Articles</h3>
    <p>
    Stodden et al. (PNAS, March 13, 2018)<br>
    204 computational articles from Science in 2011–2012
    </p>
    <img class="stretch" style="margin: 0px"; src="img/reproducibility_ratio_from_stodden.png">
    <small class="credit">
    Stodden, V., Seiler, J., &amp; Ma, Z. (2018).
    An empirical analysis of journal policy effectiveness for computational reproducibility.
    In: <em>Proceedings of the National Academy of Sciences</em>
    115(11), p. 2584-2589.
    <a href="https://doi.org/10.1073/pnas.1708290115">DOI 10.1073/pnas.1708290115</a>
    </small>
</section>

<!--
Stodden et al. (2018):
We were able to obtain data and code from the authors of 89
articles in our sample of 204, giving an estimate for the artifact
recovery rate of 44% for articles published in Science shortly
after the policy change: (65 + 24/204) with a 95% bootstrap
confidence interval of [0.36, 0.50]. Of the 56 articles that were
then deemed potentially reproducible, we randomly chose 22
to attempt replication, and all but 1 of the 22 provided enough
information that we were able to reproduce their computational
findings (given sufficient resources and a willingness write some
code). We estimate 95% (21/22) of the articles deemed reproducible
by inspection are computationally reproducible, so for
the full sample, we estimate 26% will computationally reproduce
((56 ∗ (1 − 1/22))) with a 95% bootstrap confidence interval for
the proportion [0.20, 0.32].
((56 * (1 - 1./22)) / 204)
-->

<section>
    <h3>Science and Software</h3>
    <ul>
        <li>
            code part of method description
            <small>[Ince et al. 2012, Morin et al. 2012, Nat. Methods 2007]</small>
        <li>
            use of open source tools part of reproducibility
            <small>[Less 2012, Alsberg &amp; Hagen 2006]</small>
        <li>
            <em>easily reproducible result</em> reproduced in 10 minutes
            <small>[Schwab et al. 2000]</small>
    </ul>
</section>


<section>
    <h3>State of the Art</h3>
    <img class="left" src="img/zip_with_password.png">
    <ul class="right">
        <li class="fragment">binary
            <ul>
                <li>not flexible, not transparent
            </ul>
        <li class="fragment">source code
            <ul>
                <li>not enough by itself
                <li><em>Thanks for that GitHub link.<br> What does it do?</em> <small class="credit">[Nabors 2016]</small>
            </ul>
        <li class="fragment">code repository
            <ul>
                <li>easy to delete <small>(e.g GitHub)</small> <small class="credit">[Bergman 2012]</small>
            </ul>
        <li class="fragment">virtual machine <small class="credit">[e.g., Gent 2013]</small>
            <ul>
                <li>too cumbersome <small>(large files, not descriptive)</small>
            </ul>
        <li class="fragment">web service
            <ul>
                <li>somebody needed to keep it running
            </ul>
    </ul>
</section>


<section>
    <h3>Questions</h3>
    <ul>
        <li>How to ensure reproducibility of geospatial research with many software dependencies?
        <li>Where to publish source code so it is preserved?
        <li>How to publish geospatial software so it is reusable inside and outside of academia?
        <li>How to identify a suitable software platform for building and publishing research code?
    </ul>
</section>


<section>
    <h3>Use Case</h3>
    Petras et al. 2017
    <br>
    <img class="stretch" src="img/papers/petras2017generalized_full.png">
    <br>
    <small class="credit">
        Petras, V., Newcomb, D. J., &amp; Mitasova, H. (2017).
        <em>Generalized 3D fragmentation index derived from lidar point clouds.</em>
        In: Open Geospatial Data, Software and Standards 2(1), 9.
        <a href="https://doi.org/10.1186/s40965-017-0021-8">DOI 10.1186/s40965-017-0021-8</a>
    </small>
</section>


<section>
<h3>Publication Framework</h3>
<table style="font-size: smaller;">
    <tr>
        <th>Component</th>
        <th>in the Petras et al. 2017 use case</th>
    <tr>
        <td>Text</td>
        <td>
            background, methods, results, discussion, conclusions, &hellip;
        </td>
    </tr>
    <tr>
        <td>Data</td>
        <td>
            input data <small>(formats readable by open source software)</small>
        </td>
    </tr>
    <tr>
        <td>Reusable&nbsp;code</td>
        <td>
            methods as GRASS GIS modules <small>(C &amp; Python)</small>
        </td>
    </tr>
    <tr>
        <td>Publication-specific&nbsp;code</td>
        <td>
            scripts to generate results <small>(Bash &amp Python)</small>
        </td>
    </tr>
    <tr>
        <td>Computational environment</td>
        <td>
            details about all dependencies and the code <small>(Docker, Dockerfile)</small>
        </td>
    </tr>
    <tr>
        <td>Versions</td>
        <td>
            repository with current and previous versions* <small>(Git, GitHub)</small>
        </td>
    </tr>
</table>
<p>
    <small style="font-size: 70%;">
    * Version associated with the publication included also as a supplemental file.
    </small>
</p>
</section>


<section>
    <div class="left">
    <h3>Publication-Specific Code</h3>
    <ul>
        <li>creates exact results as published in the paper
        <li>works with specific input data
        <li>Petras et al. 2017: Bash and Python scripts
    </ul>
    </div>
    <div class="right">
    <h3>Reusable Code<br>&nbsp;</h3>
    <ul>
        <li>new software for reuse
        <li>flexible reproducibility and replicability
        <li>works with any data
        <li>Petras et al. 2017: GRASS GIS modules (C and Python)
    </ul>
    </div>
</section>


<section>
    <h3>Computational Environment and Reproducibility</h3>
    <ul>
        <li>Computational environment: all dependencies specified and provided
        <li>Docker <small>(used in Petras et al. 2017)</small>:
            <ul>
                <li>similar to virtual machine: isolated &amp; self-contained environment
                <li>lightweight &amp; efficient
                <li>all dependencies described in a text file <small>(Dockerfile)</small>
            </ul>
    </ul>
    <p style="margin-top: 2em;">
        Repository linked from Petras et al. 2017 gives two steps
        for building the environment and running the code:
    <pre style="font-size: 70%;">
docker build -t forestfrag3d https://github.com/wenzeslaus/forestfrag3d.git
docker run --rm -v /home/.../ffdata:/data -it forestfrag3d /code/run.sh
</pre>
    <small>
        <a href="https://github.com/wenzeslaus/forestfrag3d">github.com/wenzeslaus/forestfrag3d</a>
    </small>
</section>

<!--
$ time docker build --no-cache -t forestfrag3d https://github.com/wenzeslaus/forestfrag3d.git
real 15m51.028s
user 0m2.000s
sys  0m1.400s
$ mkdir /tmp/testff
$ time docker run --rm -v /tmp/testff:/data -it forestfrag3d /code/run.sh
real 23m16.968s
user 0m0.416s
sys  0m0.540s
$ mkdir /tmp/testff_test_region
$ time docker run --rm -v /tmp/testff_test_region/:/data -it forestfrag3d /code/run.sh test
real 5m49.269s
user 0m0.116s
sys  0m0.200s
-->


<section>
    <h3>Reproducibility</h3>
    <ul>
        <li>executing the code gives all results for the paper
    </ul>
    <br>
    <img class="stretch" src="img/reproduced_figures_detail.png">
    <br>
    <small>
        Data-driven figures reproduced using the repository
        associated with Petras et al. 2017 paper
    </small>
</section>


<section>
    <h3>Reproducibility</h3>
    <ul>
        <li>finished recomputation at Code Ocean
    </ul>
    <br>
    <img class="stretch" src="img/codeocean_frag_interface.png">
    <small>
        Results in the <em>Interface</em> tab:
        <a href="https://codeocean.com/2018/04/21/generalized-3d-fragmentation-index-derived-from-lidar-point-clouds/interface" title="Goes directly to the capsule interface">
            codeocean.com/2018/04/21/generalized...clouds/interface
        </a>
    </small>
    <br>
    <small style="font-size: 75%;">
        Usual runtime is around 27 min.
    </small>
</section>


<section>
    <h3>Software Platform</h3>
    <ul>
        <li>Reusable code component needs a place to survive and thrive.
            <ul>
                <li>Maintenance and distribution of reusable code is time consuming.
                <li>A software platform needed as a common place for
                    long-term maintenance and distribution to facilitate reuse.
            </ul>
        <li>Platform evaluation criteria:
        <ul>
            <li>Does the contributed scientific code survive over time?
            <li>How much original research is in the software?
            <li>How easy is it for a user to inspect the underlying code?
        <li>Are preprocessing, visualization, and user interface included?
        <li>&hellip;
        </ul>
    </ul>
</section>


<section>
    <h3>Contributions</h3>
    <ul>
        <li>general publication framework for open science
            <ul>
                <li>components: text, data, reusable code, publication-specific code, computational environment, versions
            </ul>
        <li>concept of software platform for publishing and preserving scientific code
            <ul>
                <li>criteria: license, code authorship &amp; sustainability, integration, &hellip;
                <li>candidates &amp; examples: R, Octave, GRASS GIS, LANDIS-II, &hellip;
            </ul>
        <li>general, but addressing specific challenges of geospatial science
            <ul>
                <li>research has many software dependencies
                <li>software reused outside of academia
                <li>support for visualization, data formats, &hellip;
            </ul>
    </ul>
</section>


<section>
    <h3>Publications</h3>
    <h4>Published</h4>
    <p>
    Petras, V., A. Petrasova, B. Harmon, R. K. Meentemeyer, and H. Mitasova (2015).
    <em>Integrating free and open source solutions into geospatial science education</em>.
    In: ISPRS International Journal of Geo-Information 4(2), p. 942-956
    [2727 full-text views, Altmetric Attention Score 20 (in the top 25%), Apr 16, 2018]
    <h4>To Be Submitted</h4>
    <p>
    <em>
        A framework for open geospatial science (Chapter 6).
    </em>
    <br>
    Target journal:
    Environmental Modelling &amp; Software
    </p>
    <br>
    <img class="stretch" src="img/papers/petras2015integrating.png">
</section>


<section>
    <div class="left" style="font-size: smaller;">
    <h4>Related Publications</h4>
    <p>
    Rocchini, D., V. Petras, A. Petrasova, N. Horning,
    L. Furtkevicova, M. Neteler, B. Leutner, and M. Wegmann.
    <em>Open data and open source for remote sensing training in ecology</em>
    In: Ecological Informatics 40, 2017, p.&nbsp;57-61,
    <a href="https://doi.org/10.1016/j.ecoinf.2017.05.004">DOI&nbsp;10.1016/j.ecoinf.2017.05.004</a>.
    </p>
    <img style="width: 100%;" src="img/papers/rocchini2017.png">
    </div>
    <div class="right" style="font-size: smaller;">
    <h4>Related Posters</h4>
    <p>
    Petras, V., Petrasova, A. &amp; Mitasova, H.
    <em>Tools for open geospatial science.</em>
    AGU Fall Meeting Abstracts 51 (2017).
    <p>
    Petras, V., Y. Chemin, M. Landa, T. Leppelt, P. Zambelli, L. Delucchi,
    M. Di Leo, S. Gebbert, and M. Neteler (2017).
    <em>How innovations thrive in GRASS GIS</em>.
    NCGIS2017, Raleigh, NC, USA.
    <p>
    Petras et al. EGU 2015
    <br>
    Chemin et al. EGU 2015
    <br>
    Petras, V. and Gebbert, S. AGU 2014
    <br>
    </p>
    <img style="width: 100%;" src="img/papers/petras2017tools.png">
    </div>
</section>


<!-- open science course -->


<section>
    <h3>Teaching</h3>
    <ul>
        <li>Course: Tools for open geospatial science
        <ul>
            <li>
                plain text, version control systems,
                open geospatial tools, command line,
                computational notebooks, publishing source code,
                collaboration online, &hellip;
            <li>
                research focus overlapping with industry
                <small>
                (containerization, data analytics)
                </small>
            <li>
                teaching materials available online
                <small>
                    (<a href="https://ncsu-geoforall-lab.github.io/open-science-course">ncsu-geoforall-lab.github.io/open-science-course</a>)
                </small>
        </ul>
    </ul>
    <br>
    <img class="stretch" src="img/open_class_index.png">
</section>


<!-- conclusions -->


<section>
    <h3>Conclusions</h3>
    <ul>
        <li>Review and analysis of density anomalies and related errors in point clouds
        <li>Evaluation of homogenization and decimation methods for anomalies and dense point clouds
        <li>Method for 3D vegetation structure description
        <li>Software tools which implement these methods
        <li>Methods and training to understand, organize, and ensure reproducibility
    </ul>
    <br>
    <img class="stretch" src="img/dark_forest.png">
    <p><a href="https://wenzeslaus.github.io/dissertation-presentation/">wenzeslaus.github.io/dissertation-presentation</a></p>
</section>


        </div>  <!-- slides -->

    </div>  <!-- reveal -->
    <!--
        Home button or link to a parent page
        If you want this to be unique for every page (slide deck),
        then remove it from here and put it at the end of each
        file (or series of files) creating one page
        (the position will be little different)
        TODO: some JS is needed to move it to the right position
    -->
    <div class="parent-page">
        <a href="http://wenzeslaus.github.io/" title="Personal page">&#8962;</a>
    </div>

        <script src="lib/js/head.min.js"></script>
        <script src="js/reveal.js"></script>

        <script>

            // Full list of configuration options available here:
            // https://github.com/hakimel/reveal.js#configuration
            Reveal.initialize({
                // Display controls in the bottom right corner
                controls: false,

                // Display a presentation progress bar
                progress: true,

                center: true,

                // Display the page number of the current slide
                slideNumber: false,

                // Enable the slide overview mode
                overview: true,

                // Turns fragments on and off globally
                fragments: true,

                // The "normal" size of the presentation, aspect ratio will be preserved
                // when the presentation is scaled to fit different resolutions. Can be
                // specified using percentage units.
                // width: 960,
                // height: 700,

                // Factor of the display size that should remain empty around the content
                margin: 0.05,  // increase?

                // Bounds for smallest/largest possible scale to apply to content
                minScale: 0.5,
                maxScale: 5.0,

                theme: Reveal.getQueryHash().theme,  // available themes are in /css/theme
                transition: Reveal.getQueryHash().transition || 'none', // default/cube/page/concave/zoom/linear/fade/none

                // Push each slide change to the browser history
                history: true,
                // Enable keyboard shortcuts for navigation
                keyboard: true,

                // Vertical centering of slides
                center: true,

                // Enables touch navigation on devices with touch input
                touch: true,

                // Loop the presentation
                loop: false,
                // Flags if the presentation is running in an embedded mode,
                // i.e. contained within a limited portion of the screen
                embedded: false,

                // Number of milliseconds between automatically proceeding to the
                // next slide, disabled when set to 0, this value can be overwritten
                // by using a data-autoslide attribute on your slides
                autoSlide: 0,

                // Stop auto-sliding after user input
                autoSlideStoppable: true,

                // Enable slide navigation via mouse wheel
                mouseWheel: false,

                // Hides the address bar on mobile devices
                hideAddressBar: true,

                // Opens links in an iframe preview overlay
                previewLinks: false,

                // Transition speed
                transitionSpeed: 'default', // default/fast/slow

                // Transition style for full page slide backgrounds
                backgroundTransition: 'none', // default/none/slide/concave/convex/zoom

                // Number of slides away from the current that are visible
                viewDistance: 3,

                // Parallax background image
                //parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

                // Parallax background size
                //parallaxBackgroundSize: '' // CSS syntax, e.g. "2100px 900px"
                chalkboard: {
                // optionally load pre-recorded chalkboard drawing from file
                    src: "chalkboard.json",
                },
                // Optional libraries used to extend on reveal.js
                dependencies: [
                    { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
                    { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
                    { src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
                    { src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
                    //{ src: 'plugin/math/math.js', async: true },
                    { src: 'plugin/chalkboard/chalkboard.js' }
                ],
                keyboard: {
                    67: function() { RevealChalkboard.toggleNotesCanvas() },    // toggle notes canvas when 'c' is pressed
                    66: function() { RevealChalkboard.toggleChalkboard() },    // toggle chalkboard when 'b' is pressed
                    46: function() { RevealChalkboard.clear() },    // clear chalkboard when 'DEL' is pressed
                     8: function() { RevealChalkboard.reset() },    // reset chalkboard data on current slide when 'BACKSPACE' is pressed
                    68: function() { RevealChalkboard.download() },    // downlad recorded chalkboard drawing when 'd' is pressed
                },
            });

        </script>

    </body>
</html>
